# 第5期  模型部署

## 1. 配置lmdeploy运行环境

![](img/1.%E9%83%A8%E7%BD%B2%E7%8E%AF%E5%A2%83.png)



## 2. 下载internlm-chat-1.8b模型

![](img/2.%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B.png)



## 3. 以命令行方式与模型对话

![](img/3.%20%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AF%B9%E8%AF%9D.png)



## 4. KV Cache

 ![](img/4.kv%20Cache.png)



## 5. 启动API服务器

![](img/5.%E5%90%AF%E5%8A%A8API%E6%9C%8D%E5%8A%A1%E5%99%A8.png)



## 6. 命令行客户端连接服务器

![](img/6.%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8.png)



## 7. 网页客户端连接API服务器

![](img/7.%E7%BD%91%E9%A1%B5%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%BF%9E%E6%8E%A5API%E6%9C%8D%E5%8A%A1%E5%99%A8.png)



## 8. python代码集成学习

![](img/8.python%E4%BB%A3%E7%A0%81%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0.png)



## 9. 向TurboMind传递参数

![](img/9.%E5%90%91TurboMind%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0.png)

